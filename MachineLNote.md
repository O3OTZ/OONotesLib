# 机器学习

> 机器学习：使用正确的特征构建正确的模型来完成给定的任务。

## 集成学习

**Ensemble Learning**

1. 集成学习通过构建并结合多个**学习器**来完成学习任务。
2. 个体学习器通常由一个现有的学习算法从训练数据产生。
3. Boosting：串行化方法，基于先前基学习器的错误调整样本分布，来训练下一个基学习器，如此重复进行获得T个学习器，最终将T个基学习器进行加权结合。
4. Bagging：并行化方法，根据自助采样法，采样出T个含m个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器使用某种策略进行结合。
5. 融合算法：通过两种或两种以上单一算法进行嵌套，或是利用一种算法对另一种算法中的某些参数进行优化而形成的新算法。
6. 组合算法：在单一对象的训练过程，同时使用两种及以上的单一算法，再利用加权方式对不同的算法模型进行整合。

## Data Centric

1. 工业中，模型落地更需要一套成熟的数据处理流程，配合数据处理工具，以更加快速帮助算法对业务的正向帮助，以及减少算法工程师的工作量，故工业场景中，数据依赖性更高。
2. 工业中，数据稀缺，需要根据数据资源规模不同，采取不同策略，如多模态及加入人类智慧。
3. 样本生而不等，引入样本权重，来扩充样本维度，针对样本不同分度、颗粒度及标志制控等的要求，采取不同的方式。数据进步倒逼模型进步，人类的直觉经验对一些标签体系可能有误差，需要重新审视。现阶段，模型容量已经足够大，故提升当前数据的信息量，以帮助更好的近似现实，更多地对数据定义作一些质疑。创业上，把众多数据孤岛联系起来，大家共享，在此基础上，再进行模型开发。
4. 在无人驾驶这种真实落地场景下，不仅要考虑模型有效性、落地可能性，以及安全性。
5. 现实>数据>模型，数据是对现实的映射，数据可反映出事实的某种内容，但数据具有特征与样本，特征代表深度，样本代表广度。数据是有限，由于有限性，数据模拟现实往往是达不到，而模型是对数据的某种拟合。数据变了，模型也需要调整，模型更多地是为数据做分布。在通用或具有客观分布规律的场景下，模型更重要。
6. 在不同的发展阶段，Data和Model的价值是不同的，工业界一直在追学术界前沿发展，一边提高数据质量，一边学习先进技术。
7. 真实数据连接现实物理世界，现实数据存在时效性，现阶段模型都是以数据为基础进行训练，连接物理世界，未来模型可能具有模拟现实物理世界能力，自动创建数据。故现阶段，数据更重要。
8. 问题是否可以定义，可定义即现实场景，则数据更重要，不可定义则模型更重要。
9. 无论Data Centric or Model Centric，在不同场景，不同条件，不同现实发展阶段中，所起价值和作用皆是不同。的确，模型在学术界与探索范式前沿更为重要，数据在工业界的落地场景更为重要。模型与数据互为动力，在矛盾中螺旋上升，辩证地不断发展。
10. 深度学习调参是基于经验的过程

## SOTA、Benchmark、Baseline

1. **SOTA**：全称为 state of the art，指在特定任务中，目前表现最好的方法或模型。
2. **Benchmark**：指基准指标
3. **Baseline**：指基准方法

**解析：**
- 你论文的motivation来自于想超越现有的baseline/benchmark，你的实验数据都需要以baseline/benckmark为基准来判断是否有提高。
- baseline讲究一套方法，而benchmark更偏向于一个目前最高的指标，比如precision，recall等等可量化的指标。
- 举个例子：NLP任务中BERT是目前的SOTA，你有idea可以超过BERT。那在论文中的实验部分你的方法需要比较的baseline就是BERT，而需要比较的benchmark就是BERT具体的各项指标。

## 时滞效应

**含义：** 时滞是时间滞后的简称，时滞是指行动与其效果之间的时间距离。

## 建模

1. 加法模型与乘积模型

## SVM

1、支持向量机的基本型：
$$
\begin{array}{l}
\mathop {\min }\limits_{\omega ,b} \frac{1}{2}{\left\| \omega  \right\|^2}\\
s.t.\\
{y_i}\left( {{\omega ^{\rm{T}}}{x_i} + b} \right) \ge 1,i = 1,2, \ldots ,m.
\end{array}
$$
2、Support Vector Machine = Hinge Loss + Kernel Method。
3、在做logistic regression时，不会使用Square loss作为Loss损失函数，因为它的Performance不好，而会使用Cross entr、opy作为Loss。
4、结构化支持向量机(Structured SVM)是线性结构的。
5、SVM可解决模式识别问题和非线性回归估计问题。

## LSSVM

**最小二乘支持向量机**
LSSVM 和 SVM的区别：LSSVM 把 SVM 的不等式约束变为等式约束，SVM 是 QP 问题，LSSVM 则是解线性方程组的问题。
**LSSVM用于分类任务：**
$$
\begin{array}{l}
\mathop {\min }\limits_{\omega ,b,e} J\left( {\omega ,e} \right) = \frac{1}{2}{\omega ^{\rm{T}}}\omega  + \gamma \frac{1}{2}\sum\limits_{i = 1}^N {e_i^2} \\
s.t.\\
{y_i}\left[ {{\omega ^{\rm{T}}}\varphi ({x_i}) + b} \right] = 1 - {e_i},i = 1,2, \ldots ,m.
\end{array}
$$
**LSSVM用于回归任务：**
$$
\begin{array}{l}
\mathop {\min }\limits_{\omega ,b,e} J\left( {\omega ,e} \right) = \frac{1}{2}{\omega ^{\rm{T}}}\omega  + \gamma \frac{1}{2}\sum\limits_{i = 1}^N {e_i^2} \\
s.t.\\
{y_i} = {\omega ^{\rm{T}}}\varphi ({x_i}) + b + {e_i},i = 1,2, \ldots ,m.
\end{array}
$$


## 多项式回归

1、多项式回归，回归函数是回归变量多项式的回归。
2、多项式回归Polynomial Regression，研究一个因变量与一个或多个自变量间多项式的回归分析方法。
3、多项式回归模型是线性回归模型的一种，其回归函数关于回归系数是线性的。
4、任一函数都可以用多项式逼近。
5、多项式回归问题可以通过变量转换，化为多元线性回归问题来解决。

## 线性回归

### 线性回归模型必须符合的条件

#### 线性性

##### 线性性判断

常用残差图判断线性性，一般用有关${{\hat y}_i}$的残差图。如果残差图的点以大致恒定的方差，大致成对称地分布在x轴附近，则使用线性回归有可能是合理的，否则不应使用线性回归。

##### 非线性性修正方法

对于不满足线性性的数据强行使用线性回归模型会导致一个非常不准确的结果，在使用此模型做外部推断或者说样本外预测时会得到错误的数值。
以下是几种常用的办法来修正数据使得它符合线性性要求：

1. 对响应变量或者预测变量或者对于两者同时使用合适的非线性变换。
   比如说，如果某个变量的值全部都是正的，可以考虑log变换，如果变量大于等于0，则可以考虑log+1变换。
   **举例：**在调查价格和需求的关系时，经常会发现预测变量的百分比变化会导致响应变量发生相应的百分比变化而且两个变化之间竟然是成近似正比的关系，这时对解释变量和预测变量同时使用log变化再对变化后的变量搞一个线性回归就很合理了。
2. 可以考虑造一些新的预测变量加入到数据中。
   使得新加入的变量与已有的预测变量x有某种非线性关系。比方说，加入x^2^或者x^3^或者甚至于更高阶的。但这个办法常常会引入过拟合的问题。
3. 在收集数据的时候漏掉了很重要的预测变量。
   这些变量可能与响应变量有很大的关系，或者跟其他的预测变量的交互能够很好的解释响应变量。
   **举例：**金融机构里搞时间序列模型，经常会有这种情况，数据实际上是应该分成一段一段的，每一段上有一个明显的线性关系，但是把每一段全部合在一起看，并不存在一个简单的线性关系。那么，如果我们能对数据进行正确的分段并且加入一个示性变量来表示观测值属于哪一段，那么最终得到的模型就是分段线性回归模型，此时的数据模拟与预测就是准确的了。当然，正如前面所说，随着新变量的加入，modeler需要时时关注过拟合的程度，找到一个好的平衡点。

#### 误差项的独立性

##### 误差项的独立性解析

- 不同的观测对应的误差项应该是相互独立的。
- 这点在金融数据上往往是得不到保证的。
- 举例：考虑股票的价格，那么今天的价格很有可能跟昨天或者前天或者一个星期以前的股价有某些关系。为了说明问题，把事情搞极端一点，假设线性回归的拟合结果处处为0，那么每天的误差值直接就等于每天股价的观测值，而按照上面所说，每天的观察值之间存在某些关系，那么很明显，误差项的独立性假设被违反了。

##### 测试数据独立性的方法

- 画残差的时间序列图（Residual time series plot）或者残差的自相关图（Residual Autocorrelation Function plot，R-ACF）。自相关图阐述了一个变量与其自身在不同时间点的观测的互相关关系。比如考虑滞后n天的自相关就是研究股票今天的价格和n天前的价格之间的相关关系。如果ACF图中的某些滞后对应的自相关超过了95%的置信区间，那么独立性假设就被违反了。
- Durbin-Watson检验。这个检验只用于检查股票的滞后1天的自相关强度。其统计量大致等于2(1-a)，其中a是滞后1天的样本自相关强度。如果残差是独立的，那么统计量应该约等于2，所以如果对于一个50样本量的数据来说，此统计量超过1.4~2.6的范围，则认为独立性假设被违反了。

##### 解决独立性被违反问题

- 有不是太明显的正的自相关
  即Durbin-Watson统计量虽然不在1.4-2.6范围内，但是比1.4小的不多的情况下（比如1.3），那么可以对现有模型进行一些小幅度的调整。比如在使用线性回归之前，先对数据使用诸如ARIMA(p,d,q)模型进行拟合，对这个时间序列的残差再使用线性回归，然后再更新DW统计量。可以考虑对所有的p<=5,d<=3,q<=5的组合都这么算一遍，找出使得更新了的DW统计量落在1.4-2.6的范围之间的(p,d,q)的组合。
- 有明显的负的自相关
  即DW统计量>2.6。说明可能对响应变量做了过度的差分处理。我们知道，过度的差分甚至于可以让本来毫不相关的数据变得有关联。这就迫使我们停下来想一想是不是有必要对变量做那么高阶的差分。
- 有非常明显的正的自相关
  即DW统计量<1.0，那你就应该很认真的在心里打起退堂鼓了，直接调用线性回归很可能就错大发了。这个时候你应该好好的再审视一下你的数据或者你的预处理的步骤，比方说你就应该再想想对变量该不该做差分，做几阶差分，或者该不该做log变换之类的问题。调整你的预处理策略再看看更新的DW统计量会不会变好。
- 有明显的季节性相关
  比方对说包含每月观测值的数据可能以滞后12为间隔表现出相关性。
  那么一种办法是先以12为间隔进行差分，然后在对差分以后的数据使用线性回归。
  另一种办法是引入示性变量来显示当前的观测的月份。这个时候再调用线性回归就能自动在每年的一月份上加上一个调整参数，二月份上加上一个不同的调整参数，然后三月，四月，以此类推。这样就在一定程度上减轻了因为月份相同所带来的季节性相关性。

#### 同方差性

**同方差性：**误差项的方差是一样的。

##### 检测同方差性假设是否成立的方法：

- 画残差与预测值的对比图、或残差与时间的对比图、或残差与预测变量的对比图
- 如果残差随着预测值、或者时间、或者预测变量的增加而单调递增，那说明同方差性被违背

##### 解决违背同方差性时产生的问题：

- 使用加权最小二乘法对变动比较小的观测值强行赋予较大的权重，增加它们在参数估计中所占的比重
- 对那些高度扭曲的数据，可以考虑使用log变换

#### 正态性

**正态性：**要求误差项来自正态分布。对于小样本，需要检测正态分布，而当样本量增大，正态分布假设越来越不重要。

##### 检测正态性的方法：

- 画正态分位数图
- 传统的统计测试

##### 解决正态性不满足的问题

- 把各变量做log
- 把数据进行分段，使每一段正态性得到满足

##### 加符合正态分布的随机噪声

```python
'''
线性回归的假设前提是，因变量是或近似是正态分布，当噪声服从正态分布N(0,δ^2)时，因变量则服从正态分布N(ax(i)+b,δ^2)，其中预测函数y=ax(i)+b。
'''
import numpy as np
def true_fun(X):
  return 1.5*X + 0.2
np.random.seed(0)
n_samples = 30
#生成随机数据rand()作为训练集，同时加一些服从正态分布的随机噪声randn()。
X_train = np.sort(np.random.rand(n_samples))
y_train = (true_fun(X_train) + np.random.randn(n_samples)* 0.05).reshape(n_samples, 1)
```

#### 多重共线性

## 差分进化算法

**简述：**差分进化DE与遗传算法GA非常相似，差分使用基于种群的全局搜索策略，采用实数编码、基于差分的简单变异操作（区别于遗传算法的重要标志）和一对一的竞争生存策略。
**变异操作：**在DE中，常见的差分策略是随机选取种群中两个不同的个体，将其向量差 缩放后与待变异个体进行向量合成，即
$$
\begin{array}{l}
{v_i}\left( {g + 1} \right) = {x_{r1}}\left( g \right) + F \bullet \left( {{x_{r2}}\left( g \right) - {x_{r3}}\left( g \right)} \right)\\
i \ne {r_1} \ne {r_2} \ne {r_3}
\end{array}
$$
​	其中，F为缩放因子，${x_{i}}\left( g \right)$表示第g代种群中第i个个体。

## LSTM

![](E:\Python&Algorithm\Dat&AlgorithmNote_image\LSTM的细胞结构和运算.jpg)

```python
#LSTM的python伪代码
'''
1.首先，将先前的隐藏状态和当前的输入连接起来，称为combine。
2.将combine丢到遗忘层中，用于删除不相关的数据。
3.再将combine丢到候选层中，候选层包含着可能要添加到细胞状态中的值。
4.将combine丢到输入层，该层决定候选层中哪些数据需要添加到新的细胞状态中。
5.接下来细胞状态再根据遗忘层、候选层、输入层以及先前细胞状态的向量来计算。
6.再计算当前细胞的输出。
7.最后将输出与新的细胞状态逐点相乘以得到新的隐藏状态。'''
def LSTMCELL(prev_ct, prev_ht, input):
    combine = prev_ht + input
    ft = forget_layer(combine)
    candidate = candidate_layer(combine)
    it = input_layer(combine)
    Ct = prev_ct * ft + candidate * it
    ot = output_layer(combine)
    ht = ot * tanh(Ct)
    return ht, Ct

ct = [0, 0, 0]
ht = [0, 0, 0]
for input in inputs:
    ct, ht = LSTMCELL(ct, ht, input)
```



## Keras

### 主要步骤

使用Keras解决机器学习/深度学习问题的主要步骤：
1、特征工程 + 数据划分
2、搭建神经网络模型add
3、查看网络架构summary
4、编译网络模型compile
5、训练网络fit
6、保持模型save
7、评估模型evaluate
8、评价指标可视化visualize

### 数据标准化

针对测试集的数据处理：使用训练集的均值和标准差。

## 数据预处理

### 特征工程

1、通常特征工程分为特征提取、特征选择、特征构建。
2、特征提取与特征选择
Feature extraction是在原有特征集基础之上去创造凝练出一些新的特征出来。
Feature selection只是在原有特征集上进行筛选。

### Data Augmentation

1、Flip：快速翻转——图像对称或旋转180°。
2、Rotation：旋转——图像以某个角度旋转一定角度，旋转后，图像尺寸可能无法保留。
3、Scale：缩放——图像向内或向外缩放。
4、Crop：随机裁剪——从原始图像中随机抽样一部分，后将此部分的大小调整为原始图像大小。
5、Translation：翻译——翻译只涉及沿X或Y方向（或两者）移动图像。
6、Gaussion Noise：高斯噪声——向图像添加高斯噪声，添加适量的噪声可以增强学习能力。

### One-Hot

**One-Hot编码：**独热编码，又称一位有效编码。使用 N位 状态寄存器来对 N个状态 进行编码，每个状态都有它独立的寄存器位，并且在任意时候，其中只有一位有效（即为 1 ）。
**解析：**One-Hot编码是 **分类变量** 作为 **二进制向量** 的表示。
			（1）将分类值映射为整数值。
			（2）将每个整数值表示为二进制向量，方法为整数值在向量中的位置设为1，其他位置均设为0。
**举例：**
性别特征：[男，女]
						男 -> 1 -> 10
						女 -> 2 -> 01
颜色特征：[红，黄，蓝，绿]
						红 -> 1 -> 1000
						黄 -> 2 -> 0100
						蓝 -> 3 -> 0010
						绿 -> 4 -> 0001
[男，蓝] -> [1, 0, 0, 0, 1, 0]

### Feature Scaling

<!--可称为“特征缩放”、“特征归一化”、“标准化”-->

#### Feature Scaling的必要性

- **特征间的单位（尺度）可能不同**。在进行距离有关的计算时，单位的不同会导致计算结果的不同，尺度大的特征会起决定性作用，而尺度小的特征其作用可能会被忽略，为了消除特征间单位和尺度差异的影响，以对每维特征同等看待，需要对特征进行**归一化**。
- **原始特征下，因尺度差异，其损失函数的等高线图可能是椭圆形**，梯度方向垂直于等高线，下降会走zigzag路线，而不是指向local minimum。通过对特征进行**标准化**（zero-mean和unit-variance）变换后，其损失函数的等高线图更接近圆形，梯度下降的方向震荡更小，收敛更快。

​            <img src="E:\Python&Algorithm\Dat&AlgorithmNote_image\FeatureScaling等高线图.png" alt="FeatureScaling等高线图"  />

#### 常用Feature Scaling方法

​		feature scaling的方法可以分成2类，逐行进行和逐列进行。逐行是对每一维特征操作，逐列是对每个样本操作。
​		以下，前3种为逐行操作，最后1种为逐列操作。

##### 尺度变换(最小-最大归一化&区间缩放)

**Rescaling（min-max normalization、range scaling）**
$$
x' = a + \frac{{(x - \min (x))(b - a)}}{{\max (x) - \min (x)}}
$$
​		将每一维特征线性映射到目标范围[a, b]，即将最小值映射为a，最大值映射为b，常用目标范围为[0, 1]和[-1, 1]，特别地，映射到[0, 1]计算方式为：
$$
x' = \frac{{x - \min (x)}}{{\max (x) - \min (x)}}
$$

##### 均值归一化

**Mean Normalization**
$$
x' = \frac{{x - \bar x}}{{\max (x) - \min (x)}}
$$
​		将均值映射为0，同时用最大值最小值的差对特征进行归一化。
​		另一种更常见的做法是用标准差进行归一化，如下。

##### 标准化

**Standardization（Z-score Normalization）**
$$
x' = \frac{{x - \bar x}}{\sigma }
$$

- 每维特征0均值1方差（zero-mean and unit-variance）
- 标准化将数据变换为0均值1方差的分布，不一定是标准正态分布，取决于原始数据的分布。
- 标准化和归一化都不会改变原始数据排列顺序的线性变换。
- ${\bar x}$是均值，${\sigma }$是标准差。

##### 单位长度缩放

**Scaling to unit length**
$$
x' = \frac{x}{{\left\| x \right\|}}
$$
​		将每个样本的特征向量除以其长度，即对样本特征向量的长度进行归一化，长度的度量常使用的是L2 norm（欧氏距离），有时也会采用L1 norm。

##### 对比分析

​		前3种feature scaling的计算方式为减一个统计量再除以一个统计量，最后1种为除以向量自身的长度。

- **减一个统计量**可以看成**选哪个值作为原点**，是**最小值还是均值**，并**将整个数据集平移到这个新的原点位置**。如果特征间偏置不同对后续过程有负面影响，则该操作是有益的，可以看成是**某种偏置无关操作**；如果原始特征值有特殊意义，比如稀疏性，该操作可能会破坏其稀疏性。
- **除以一个统计量**可以看成在**坐标轴方向上对特征进行缩放**，用于**降低特征尺度的影响**，可以看成是**某种尺度无关操作**。缩放可以使用最大值最小值间的跨度，也可以使用标准差（到中心点的平均距离），前者对outliers（异常值）敏感，outliers对后者的影响与outliers的数量和数据集大小有关，outliers越少数据集越大，影响越小。
- **除以长度**相当于把长度归一化，**把所有样本映射到单位球上**，可以看成是某种**长度无关操作**，比如，词频特征要移除文章长度的影响，图像处理中某些特征要移除光照强度的影响，以及方便计算余弦距离或内积相似度等。
- zero-mean将数据集平移到原点，unit-variance使每维特征上的跨度相当。两维特征间存在线性相关性，Standardization操作并没有消除这种相关性。
- 可通过PCA方法移除线性相关性（decorrelation），即引入旋转，找到新的坐标轴方向，在新坐标轴方向上用“标准差”进行缩放，最后将所有样本映射到单位球上——unit length。
         ![PCA数据处理](E:\Python&Algorithm\Dat&AlgorithmNote_image\PCA数据处理.png)

##### 小结

​		**归一化/标准化的目的**是为了获得某种“无关性”——偏置无关、尺度无关、长度无关等。当归一化/标准化方法背后的物理意义和几何含义与当前问题的需要相契合时，其对解决问题就有正向作用，反之，就会起到反作用。所以，“何时选择何种方法”取决于待解决的问题，即problem-dependent。

#### 需要Feature Scaling的情况

（1）**涉及或隐含距离计算的算法**，比如K-means、KNN、PCA、SVM等，一般需要feature scaling，因为

- zero-mean一般可以增加样本间余弦距离或者内积结果的差异，区分力更强，假设数据集集中分布在第一象限遥远的右上角，将其平移到原点处，可以想象样本间余弦距离的差异被放大了。在模版匹配中，zero-mean可以明显提高响应结果的区分度。
- 就欧式距离而言，增大某个特征的尺度，相当于增加了其在距离计算中的权重，如果有明确的先验知识表明某个特征很重要，那么适当增加其权重可能有正向效果，但如果没有这样的先验，或者目的就是想知道哪些特征更重要，那么就需要先feature scaling，对各维特征等而视之。
- 增大尺度的同时也增大了该特征维度上的方差，PCA算法倾向于关注方差较大的特征所在的坐标轴方向，其他特征可能会被忽视，因此，在PCA前做Standardization效果可能更好。

（2）**损失函数中含有正则项时，一般需要feature scaling**，因为

- 对于线性模型$y = \omega x + b$而言，$x$的任何线性变换（平移、放缩），都可以被$\omega $和$b$“吸收”掉，理论上，不会影响模型的拟合能力。但是，如果损失函数中含有正则项，如$\lambda {\left\| \omega  \right\|^2}$，λ为超参数，其对$\omega $的每一个参数施加同样的惩罚，但对于某一维特征${x_i}$而言，其scale越大，系数${\omega _i}$越小，其在正则项中的比重就会变小，相当于对${\omega _i}$惩罚变小，即损失函数会相对忽视那些scale增大的特征，这并不合理，所以需要feature scaling，使损失函数平等看待每一维特征。

（3）**梯度下降算法，需要feature scaling**。梯度下降的参数更新公式如下，
$$
W(t + 1) = W(t) - \eta \frac{{dE\left( W \right)}}{{dW}}
$$
​		E(W) 为损失函数，收敛速度取决于：参数的初始位置到local minima的距离，以及学习率η的大小。一维情况下，在local minima附近，不同学习率对梯度下降的影响如下图所示，
​               <img src="E:\Python&Algorithm\Dat&AlgorithmNote_image\梯度下降法不同学习率影响.png" alt="梯度下降法不同学习率影响" style="zoom:150%;" />
​		多维情况下可以分解成多个上图，每个维度上分别下降，参数W为向量，但学习率只有1个，即所有参数维度共用同一个学习率（暂不考虑为每个维度都分配单独学习率的算法)。**收敛意味着在每个参数维度上都取得极小值，每个参数维度上的偏导数都为0，但是每个参数维度上的下降速度是不同的，为了每个维度上都能收敛，学习率应取所有维度在当前位置合适步长中最小的那个**。

- zero center与参数初始化相配合，缩短初始参数位置与local minimum间的距离，加快收敛。
- 对于损失函数为二阶，不同方向上的下降速度变化不同（二阶导不同，曲率不同)，恰由输入的协方差矩阵决定，feature scaling改变了损失函数的形状，减小不同方向上的曲率差异。将每个维度上的下降分解来看，给定一个下降步长，如果不够小，有的维度下降的多，有的下降的少，有的还可能在上升，损失函数的整体表现可能是上升也可能是下降，就会不稳定。scaling后不同方向上的曲率相对更接近，更容易选择到合适的学习率，使下降过程相对更稳定。
- 椭圆形和圆形等高线图，仅在采用均方误差的线性模型上适用，其他损失函数或更复杂的模型，如深度神经网络，损失函数的error surface可能很复杂，并不能简单地用椭圆和圆来刻画，所以用它来解释feature scaling对所有损失函数的梯度下降的作用，似乎过于简化。
- 对于损失函数不是均方误差的情况，只要权重w与输入特征x间是相乘关系，损失函数对w的偏导必然含有因子x，w的梯度下降速度就会受到特征x尺度的影响。理论上为每个参数都设置上自适应的学习率，可以吸收掉x尺度的影响，但在实践中出于计算量的考虑，往往还是所有参数共用一个学习率，此时x尺度不同可能会导致不同方向上的下降速度悬殊较大，学习率不容易选择，下降过程也可能不稳定，通过scaling可对不同方向上的下降速度有所控制，使下降过程相对更稳定。

（4)**对于传统的神经网络，对输入做feature scaling也很重要**，因为

- 采用sigmoid等有饱和区的激活函数，如果输入分布范围很广，参数初始化时没有适配好，很容易直接陷入饱和区，导致梯度消失，所以，需要对输入做Standardization或映射到[0,1]、[−1,1]，配合精心设计的参数初始化方法，对值域进行控制。但自从有了Batch Normalization，每次线性变换改变特征分布后，都会重新进行Normalization，似乎可以不太需要对网络的输入进行feature scaling了？但习惯上还是会做feature scaling。

#### 不需要Feature Scaling的情况

（1）与距离计算无关的概率模型，不需要feature scaling，比如Naive Bayes；
（2）与距离计算无关的基于树的模型，不需要feature scaling，比如决策树、随机森林等，树中节点的选择只关注当前特征在哪里切分对分类更好，即只在意特征内部的相对大小，而与特征间的相对大小无关。

#### 何时Standardization&何时Normalization

- 如果对处理后的数据范围有严格要求，那肯定是归一化。
- 个人经验，标准化是ML中更通用的手段，如果你无从下手，可以直接使用标准化。
- 如果数据不为稳定，存在极端的最大最小值，不要用归一化。
- 在分类、聚类算法中，需要使用距离来度量相似性的时候、或者使用PCA技术进行降维的时候，标准化表现更好。
- 在不涉及距离度量、协方差计算的时候，可以使用归一化方法。

### 重复值处理

1. 数据清洗一般先从重复值和缺失值开始处理
2. 重复值一般采取删除法来处理

### 缺失值处理

1. 缺失值首先需要根据实际情况定义
2. 可以采取直接删除法
3. 有时候需要使用替换法或者插值法
4. 常用的替换法有均值替换、前向、后向替换和常数替换

### 异常值处理

1. 指那些偏离正常范围的值，不是错误值
2. 异常值出现频率较低，但又会对实际项目分析造成偏差
3. 异常值一般用箱线法（分位差法）或者分布图（标准差法）来判断
4. 异常值往往采取盖帽法或者数据离散化

### 数据离散化处理

1. 数据离散化就是分箱
2. 常用分箱方法：等频分箱、等宽分箱
3. 一般使用`pd.cut`或者`pd.qcut`

### 数据清洗步骤

1. 数据获取：使用`read_csv`或者`read_excel`
2. 数据探索：使用`shape`，`describe`或者`info`函数
3. 行列操作：使用`loc`或者`iloc`函数
4. 数据整合：对不同数据源进行整理
5. 数据类型转换：对不同字段数据类型进行转换
6. 分组汇总：对数据进行各个维度的计算
7. 处理重复值、缺失值和异常值以及数据离散化

### 数据清洗所用函数

1. `merge`，`concat`函数常常用于数据整合
2. `pd.to_datetime`常常用于日期格式转换
3. `str`函数用于字符串操作
4. 函数`astype`用于数据类型转换
5. 函数`apply`和`map`用于更加高级的数据处理
6. `Groupby`用于创建分组对象
7. 透视表函数`pd.pivot_table`和交叉表`pd.crosstab`
8. 分组对象和`agg`结合使用，统计需要的信息

### 数据清洗总结

​		数据清洗实质上是将实际业务问题中，脏数据清洗干净，转换为“干净的数据”，所谓的脏，指数据可能存在以下几种问题（主要问题）:

1. 数据缺失（Incomplete） 是属性值为空的情况。如 Occupancy = “ ”
2. 数据噪声（Noisy）是数据值不合常理的情况。如 Salary = “-100”
3. 数据不一致（Inconsistent）是数据前后存在矛盾的情况。如 Age =“042”或者Birthday =“01/09/1985”
4. 数据冗余（Redundant）是数据量或者属性数目超出数据分析需要的情况
5. 离群点/异常值（Outliers）是偏离大部分值的数据
6. 数据重复是在数据集中出现多次的数据

### 机器学习项目清单

**八大步骤：**

1. 框出问题，并看整体
2. 获取数据
3. 研究数据，以获得深刻见解
4. 准备数据，以便更好地将潜在的数据模式提供给机器学习算法
5. 探索许多不同的模型，并列出最佳模型
6. 微调模型，并将它们组合成一个很好的解决方案
7. 演示你的解决方案
8. 启动、监视和维护你的系统

### 其他

1、Batch Normalization、Layer Normalization、Series Stationarization等这些Normalization的方式都是先归一化（Normalization）后又进行逆归一化（De-normalization），只不过时间序列中逆归一化的参数不是学习的，是归一化时的统计量得到的，这也符合直觉，即输入序列的均值和方差应该和输出序列的均值和方差大致相同。

## 机器学习Tips

### 过程&步骤

#### 三步骤

Step1：Function set（Model）with unknown 含未知参数的函数集
Step2：define Loss Function 损失函数 from training data
Step3：optimization

#### 典型机器学习构建过程

1. 源数据ETL

   Extract-Transform-Load，描述将数据从来源端经过抽取（extract）、转换（transform）、加载（load）至目标端的过程。

2. 探索性数据分析
   exploratory data analysis，EDA。画图查看响应变量（responsevariable）和预测变量（predictor variable）大概长什么样，以及各变量之间存在什么样的关系，这样可以对数据有个大致的了解，同时也为后面的数据预处理（datapreprocessing）和数据建模（modelling）指出了一个大概的方向。

3. 数据预处理
   数据预处理（data preprocessing），或称feature engineering（特征工程）。比如对变量进行标准化处理，对缺失值进行处理，基于某些规则选择有效变量，对于大型数据有时候可能还会涉及到主成分分析（PCA）之类的降维方法，在尽量保持原有数据信息的情况下把它压缩成一个小一点的更容易处理的数据，等等。
   总之预处理的目的就是希望把整个数据变得更加的干净（clean）从而能够被统计模型更好的学习，建立的模型也会更加的稳定和准确。

4. 特征选取

5. 模型选择

6. 模型训练与验证

### 模型验证方法

#### 数据全为训练集

​		把数据集全部作为训练集，然后用训练集训练模型，用训练集验证模型（如果有多个模型需要进行选择，那么最后选出训练误差最小的那个模型作为最好的模型）。
（1）这种方式显然不可行，因此训练集数据已经在模型拟合时使用过了，再使用相同的数据对模型进行验证，其结果必然是过于乐观的。

#### 数据分为训练和测试集

​		把数据集随机分为训练集和测试集，然后用训练集训练模型，用测试集验证模型（如果有多个模型需要进行选择，那么最后选出测试误差最小的那个模型作为最好的模型）。
（1）什么样的模型是好的？显然泛化误差最小的模型最好，但是没有这样的测试集能够测出模型的泛化误差。因此，会把一部分数据作为测试集，用它的误差来模拟泛化误差。
（2）把数据分出一部分作为测试集，意味着训练集比原来小了。由学习曲线可知，使用较少的数据训练出来的模型，其测试误差会比较大。
（3）该验证方式对于多个模型的评估和选择，合理的做法是：用训练集训练出各个模型后，用测试集选出其中最好的模型，记录最好模型的各项设置（比如所使用的算法、迭代次数、学习速率、特征转换的方式、正则化方式、正则化系数等等），然后用整个数据集再训练出一个新模型，作为最终的模型，这样得出的模型效果会更好，其测试误差会更接近于泛化误差。
（4）大部分资料把数据分为训练集（70%-80%）和测试集（20%-30%）。这样做的前提是：把模型各个可能的设置分别列出来，训练出各个不同的模型，然后用测试集选出最好的模型，接下来用全部数据按照最好模型的各项设置重新训练出一个最终的模型。
（5）第（4）点做法有两个问题。**第一**，模型的超参数通常很多，不太有可能把所有可能的设置全部罗列出来，超参数通常需要根据实际情况进行调整。如果模型的测试成绩不理想，那么需要返回，重新训练模型。虽然测试集不用于模型的训练，但是如果基于测试误差来不断调整模型，这样会把测试集的信息带入到模型中去。显然，这样是不可行的，因为测试集必须是我们从未见过的数据，否则得出的结果就会过于乐观，即会导致过拟合的发生。**第二**，得出的最终的模型，其泛化误差是多少？还是无法评估。因为又把全部数据重新训练出了这个最终的模型，因此也就没有从未见过的数据来测试这个最终的模型。

#### 数据分为训练、验证和测试集

​		把数据集随机分为训练集、验证集和测试集，然后用训练集训练模型，用验证集验证模型，根据情况不断调整模型，选择出最好的模型，再用训练集和验证集数据训练出一个最终的模型，最后用测试集评估最终的模型。
（1）在第2种方式中，已经把数据集分为了训练集和测试集，现在需要再分出一个测试集，用于最终模型的评估。因为已经有一个测试集了，因此把其中一个用于模型选择的测试集改名叫验证集，以防止混淆。
（2）首先用训练集训练出模型，然后用验证集验证模型（注意：这是一个中间过程，此时最好的模型还未选定），根据情况不断调整模型，选出其中最好的模型（验证误差用于指导我们选择哪个模型），记录最好的模型的各项设置，然后据此再用（训练集+验证集）数据训练出一个新模型，作为最终的模型，最后用测试集评估最终的模型。
（3）由于验证集数据的信息会被带入到模型中去，因此，验证误差通常比测试误差要小。同时需要记住的是：测试误差是得到的最终结果，即便对测试得分不满意，也不应该再返回重新调整模型，因为这样会把测试集的信息带入到模型中去。
（4）该方法又称为**留出法**（Holdout Validation），留出法从数据集中抽出一部分作为验证集，但其数据没有被交叉使用（既用作训练，又用作验证），故不算作交叉验证。
（5）通常情况下，把训练集、验证集、测试集划分为70%、10%、20%。

#### 交叉验证

​		交叉验证，简单来说就是重复使用数据。除去测试集，把剩余数据进行划分，组合成多组不同的训练集和验证集，某次在训练集中出现的样本下次可能成为验证集中的样本，这就是所谓的“交叉”。最后**用各次验证误差的平均值作为模型最终的验证误差**，即**交叉验证的均方根误差**（cross validation root mean square error, CVRMSE），这个CVRMSE越小的模型对数据的拟合越精确。
​		**交叉验证原因：**当<u>数据量较少</u>，在留出法中，如果验证集较大，那么训练集就会变得很小，如果数据集本身就不大的话，显然这样训练出来的模型就不好。如果验证集很小，那么此验证误差就不能很好地反映出泛化误差。此外，在不同的划分方式下，训练出的不同模型的验证误差波动也很大（方差大）。到底以哪次验证误差为准？无法知道。但是如果将这些不同划分方式下训练出来的模型的验证过程重复多次，得到的平均误差可能就是对泛化误差的一个很好的近似。
​		交叉验证的几种方法：
（1）**留一法**（Leave One Out Cross Validation，LOOCV）
​		假设数据集一共有<u>m个样本</u>，依次从数据集中选出<u>1个样本</u>作为验证集，其余m-1个样本作为训练集，这样进行m次单独的模型训练和验证，最后将m次验证结果取平均值，作为此模型的验证误差。
​		<!--这里说的数据集都是指已经把测试集划分出去的数据集，下同-->
​		留一法的优点是结果近似无偏，这是因为几乎所有的样本都用于模型的拟合。缺点是计算量大。假如m=1000，那么就需要训练1000个模型，计算1000次验证误差。因此，当数据集很大时，计算量是巨大的，很耗费时间。除非数据特别少，一般在实际运用中不太用留一法。
（2）**K折交叉验证**（K-Fold Cross Validation）
​		把数据集分成<u>K份</u>，每个子集互不相交且大小相同，<u>依次</u>从K份中选出<u>1份</u>作为验证集，其余K-1份作为训练集，这样进行K次单独的模型训练和验证，最后将K次验证结果取平均值，作为此模型的验证误差。当K=m时，即为留一法，故留一法时K折交叉验证的特例。
​		根据经验，K一般取10。（在各种真实数据集上进行实验发现，10折交叉验证在偏差和方差之间取得了最佳的平衡）
​          <img src="E:\Python&Algorithm\Dat&AlgorithmNote_image\K折交叉验证.png" alt="K折交叉验证" style="zoom: 67%;" />

（3）**多次K折交叉验证**（Repeated K-Fold Cross Validation）
每次用不同的划分方式划分数据集，每次划分完后的其他步骤和K折交叉验证一样。如：10 次10 折交叉验证，即每次进行10次模型训练和验证，这样一共做10次，也就是总共做100次模型训练和验证，最后将结果平均。这样做的目的是让结果更精确一些。（研究发现，重复K折交叉验证可以提高模型评估的精确度，同时保持较小的偏差。）
（4）**蒙特卡洛交叉验证**（Monte Carlo Cross Validation）
		即将留出法（holdout）进行多次。每次将数据集随机划分为训练集和验证集，这样进行多次单独的模型训练和验证，最后将这些验证结果取平均值，作为此模型的验证误差。与单次验证（holdout）相比，这种方法可以更好地衡量模型的性能。与K折交叉验证相比，这种方法能够更好地控制模型训练和验证的次数，以及训练集和验证集的比例。缺点是有些观测值可能从未被选入验证子样本，而有些观测值可能不止一次被选中。（偏差大，方差小）
（5）**总结**
		在数据较少的情况下，使用K折交叉验证来对模型进行评估是一个不错的选择。如果数据特别少，那么可以考虑用留一法。当数据较多时，使用留出法则非常合适。如果需要更精确一些的结果，则可以使用蒙特卡洛交叉验证。
		**需要特别注意的是**：<u>如果要对数据进行归一化处理或进行特征选择，应该在交叉验证的循环过程中执行这些操作，而不是划分数据之前就将这些步骤应用到整个数据集</u>。
		在模型评估和模型选择过程中，验证和交叉验证除了对模型进行评估外，还起到对超参数进行优化的作用。

#### 自助法(Boostraping)

- 以自助采样法（Bootstrap Sampling）为基础，即有放回的采样或重复采样。（注：这是一种样本内抽样的方法，即将样本看作总体并从中进行抽样。）
- 自助法具体做法是：在含有 m 个样本的数据集中，每次随机挑选一个样本， 将其作为训练样本，再将此样本放回到数据集中，这样有放回地抽样 m 次，生成一个与原数据集大小相同的数据集，这个新数据集就是训练集。这样有些样本可能在训练集中出现多次，有些则可能从未出现。原数据集中大概有 36.8% 的样本不会出现在新数据集中。因此，我们把这些未出现在新数据集中的样本作为验证集。把前面的步骤重复进行多次，这样就可以训练出多个模型并得到它们的验证误差，然后取平均值，作为该模型的验证误差。
- 如果需要在多个不同的模型中进行选择，那么事先留出测试集，然后在剩余的数据集上用自助法验证模型，选择验证误差最小的模型作为最好的模型，然后用训练集+验证集数据按最好模型的设置训练出一个新的模型，作为最终的模型，最后用测试集测试最终的模型。
- 优点：训练集的样本总数和原数据集一样都是 m个，并且仍有约 1/3 的数据不出现在训练集中，而可以作为验证集。
- 缺点：这样产生的训练集的数据分布和原数据集的不一样了，会引入估计偏差。
- 用途：自助法在数据集较小，难以有效划分训练集/验证集时很有用；此外，自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处。
- 总结：Bootstraping通过重复抽样，避免了Cross Validation造成的样本减少的问题。其次，Bootstraping也可以用于随机创造数据。比如，随机森林算法就是从原始训练数据中，用bootstrap sampling的方法有放回地随机抽取k个新的自助样本集，并由此构建k棵分类回归树。但由于其训练集有重复数据，这会改变数据的分布，因而导致训练结果有估计偏差，因此这种方法不是很常用，除非数据量真的很少。
- 注：对于时间序列结构的数据，应采用block bootstrap。

### 训练&验证&测试集

- 训练集（Training dataset）：用于训练模型。
- 验证集（Validation dataset）：用于调整和选择模型。
- 测试集（Testing dataset）：用于评估最终的模型。
- 传统上，一般训练集、验证集及测试集三者的划分比例是**6:2:2**，验证集并不是必须。
- 一般来说，当把数据分成三份时，用训练集训练出模型，然后用验证集验证模型，根据情况不断调整模型，选出其中最好的模型，记录最好的模型的各项设置，然后据此再用（训练集+验证集）数据训练出一个新模型，作为最终的模型，最后用测试集评估最终的模型。
  以上是一个完整的模型评估和模型选择过程。如果**仅对单个模型进行评估**，只需要前面两个步骤：用训练集训练出模型，然后用验证集验证模型。

### 超参数

#### 什么是超参数

机器学习模型中一般有两类参数：

- 模型参数：需要从数据中学习和估计得到，即模型本身的参数。比如，线性回归直线的加权系数（斜率）及其偏差项（截距）都是模型参数。
- 超参数：机器学习算法中的调优参数，需要人为设定。比如，正则化系数，决策树模型中树的深度。

#### 参数和超参数的区别

​		模型参数是模型内部的配置参数，需要数据估计模型参数的值；模型超参数是模型外部的配置，需要手动设置超参数的值。机器学习中说的“调参”，实际不是调“参数”，而是调“超参数”。

#### 超参数有哪些

​		梯度下降法中的学习速率，迭代次数epoch，批量大小batch-size，k近邻法中的k（最相近的点的个数），决策树模型中树的深度，等等。

#### 超参数优化方法

- 试错（Babysitting）
- 网格搜索（Grid Search）
- 随机搜索（Random Search）
- 贝叶斯优化（Bayesian Optimization）

### 其他

（1）Maximize用Gradient ascent
	  Minimize用Gradient descent
（2）模型越复杂，其训练误差也就越小，当某个模型的训练误差看似很完美时，这个模型可能就已经严重过拟合。
（3）回归问题均方差MSE，分类问题交叉熵损失。
（4）当训练集中的实例相互独立且分布均匀时，梯度下降效果最佳。

# 深度学习

## batchsize/iteration/epoch

- **batchsize：**批大小。在深度学习中，一般采用SGD（随机梯度下降）训练，即每次训练时，在训练集中取batchsize个样本训练。

- **iteration：**1个iteration等于使用batchsize个样本训练一次。

- **epoch：**1个epoch等于使用训练集中的全部样本训练一次。

注：

（1）训练集有1000个样本，batchsize=10，那么：

​		训练完整个样本集需要：100次iteration，1次epoch。

（2）具体的batchsize的选取和训练集的样本数目相关。

（3）GPU对**2的幂次的batch**可以发挥更佳的性能，因此设置成16、32、64、128...时往往要比设置为10、100的倍数时表现更优。

（4）批输入数据时，当样本数量无法整除`batch_size`时，往往会丢弃掉后面的若干个样本，如在pytorch中使用`DataLoader`加载数据时，在参数里设置`drop_last=True`。
（5）通常，batchsize取32是较好的值。
（6）在调整批大小时，通过比较训练曲线（训练、验证误差与训练时间量），来优化batchsize。
（7）在调优所有其他超参数后，调优批处理大小和学习率。

## sample/batch/epoch

<!--Keras中文文档摘录-->

- **Sample：**样本，单行数据，数据集中的一条数据。它包含输入到算法中的输入和用于与预测进行比较并计算错误的输出。例如图片数据集中的一张图片，语音数据中的一段音频。

- **Batch**：（1）可译为“批”，一个batch由若干条数据构成。batch是进行网络优化的基本单位，<u>网络参数的每一轮优化需要使用一个batch</u>。batch中的样本是被并行处理的。与单个样本相比，一个batch的数据能更好的模拟数据集的分布，batch越大则对输入数据分布模拟的越好，反应在网络训练上，则体现为能让网络训练的方向“更加正确”。但另一方面，<u>一个batch也只能让网络的参数更新一次</u>，因此网络参数的迭代会较慢。在测试网络的时候，应该在条件的允许的范围内尽量使用更大的batch，这样计算效率会更高。
               （2）Batch大小是一个超参数，用于定义在更新内部模型参数之前要处理的样本数。将批处理视为循环迭代一个或多个样本并进行预测。在批处理结束时，将预测与预期输出变量进行比较，并计算误差。从该误差中，更新算法用于改进模型，例如沿误差梯度向下移动。
               （3）训练数据集可以分为一个或多个Batch。当所有训练样本用于创建一个Batch时，学习算法称为**批量梯度下降**。当批量是一个样本的大小时，学习算法称为**随机梯度下降**。当批量大小超过一个样本且小于训练数据集的大小时，学习算法称为**小批量梯度下降**。

|     算法名称      |        划分条件         |                     描述                     | 特点                                                         |
| :---------------: | :---------------------: | :------------------------------------------: | ------------------------------------------------------------ |
|   批量梯度下降    |  批量大小=训练集的大小  |       计算所有训练样本的误差后更新模型       | 对模型的更新较少，计算效率高，更稳定的收敛，但可能是早熟收敛 |
| 随机梯度下降(SGD) |       批量大小=1        |  计算每个样本误差并迭代更新每个训练样本模型  | 对模型的更新频繁，利于学习，避免早熟收敛，在大数据集上计算成本高 |
|  小批量梯度下降   | 1<批量大小<训练集的大小 | 计算每个小批量误差并迭代更新每个训练批量模型 | 对模型的更新适中，利于避免局部极小值，比SGD更有效的计算过程，但引入“批大小”超参数 |

​		（4）在小批量梯度下降的情况下，常用的批量大小包括32、64、128和256个样本。
​		（5）当数据集没有按批量大小均匀分配：在训练模型时经常会发生这种情况，它可意味着最终批次的样品数量少于其他批次，或者，也可从数据集中删除一些样本或更改批处理大小，以便数据集中的样本数按批次大小均匀划分。

- **Epoch：**（1）epoch可译为“轮次”。如果说<u>每个batch对应网络的一次更新的话，一个epoch对应的就是网络的一轮更新</u>。<u>每一轮更新中网络更新的次数可以随意，但通常会设置为遍历一遍数据集。因此一个epoch的含义是模型完整的看了一遍数据集</u>。 设置epoch的主要作用是把模型训练的整个训练过程分为若干个段，这样我们可以更好的观察和调整模型的训练。Keras中，当指定了验证集时，每个epoch执行完后都会运行一次验证集以确定模型的性能。另外，我们可以使用回调函数在每个epoch的训练前后执行一些操作，如调整学习率，打印目前模型的一些信息等，详情请参考Callback一节。
               （2）Epoch数是一个超参数，定义了学习算法在整个训练数据集中的工作次数。一个Epoch意味着训练数据集中的每个样本都有机会更新内部模型参数。Epoch由一个或多个Batch组成。
               （3）可以将for循环放在每个需要遍历训练数据集的Epoch上，在这个for循环中是另一个嵌套的for循环，它遍历每批样本，其中一个批次具有指定的“批量大小”样本数。
               （4）Epoch数通常设置为10、100、500、1000或更大，允许学习算法运行直到模型的误差被充分地最小化。
               （5）通常创建线图，其显示沿x轴的时间以及模型在y轴上的误差，该图称为学习曲线。这些图可以帮助诊断模型是否已经过度学习、学习不足或者是否适合训练数据集。

- **Batch和Epoch区别：**
  （1）Batch大小是在更新模型之前处理的样本量。Epoch数是用于训练的数据集的完整传递次数。
  （2）批处理的大小必须大于或等于1，且小于或等于训练数据集中的样本数。而Epoch可设置为1到无穷大之间的整数值。
  （3）可以根据需要运行算法，也可以使用除固定数量的Epoch之外的其他条件来停止算法，例如模型错误随时间的变化（或缺少变化）。
  （4）Batch大小和Epoch数都是整数值，且都是学习算法的超参数。必须为学习算法指定Batch大小和Epoch数，如何配置这些参数没有固定的规则，必须尝试不同的值，看看哪种最适合所研究的问题。

- **实例**
  假设有一个包含200个样本（Sample，数据行）的数据集，并且选择的Batch大小为5和1,000个Epoch。
  这意味着数据集将分为40个Batch，每个Batch有5个样本。每批5个样本后，模型权重将更新。
  这也意味着1个Epoch将涉及40个Batch（或40个模型）更新。
  有1,000个Epoch，模型将暴露或传递整个数据集1,000次。
  在整个训练过程中，总共有40,000Batch。

## 梯度下降

​		梯度下降是一种用于训练机器学习算法的优化算法，该算法的工作是找到一组内部模型参数，这些参数在某些性能测量中表现良好，例如对数损失或均方误差。
​		优化是一种搜索过程，搜索即学习。优化算法称为“梯度下降”，其中“梯度”是指误差梯度或误差斜率的计算，“下降”是指沿着该斜率向下移动到某个最小误差水平。优化算法是迭代的，意味着搜索过程发生在多个不连续的步骤上，每个步骤都希望略微改进模型参数。
​		**梯度下降的工作原理**是让模型对训练数据进行预测，并让预测上的误差以减少误差的方式更新模型。
​		**梯度下降的目标**是找到使模型在训练数据集上的误差最小的模型参数（如系数或权重）。它通过对模型进行更改来实现这一点，这些**更改**将模型沿着向下移动的梯度或误差斜率向下 移动到最小误差值。
​		进一步解释为，每一步都需要使用模型和当前的一组内部参数对一些样本进行预测，将预测与实际预期结果进行比较，计算误差，并使用误差更新内部模型参数。该更新过程对于不同的算法是不同的，但在人工神经网络中，使用反向传播更新算法。
​		**梯度下降法伪代码：**

```python
model = initialization(...)
n_epochs = ...
train_data = ...
for i in n_epochs:
    train_data = shuffle(train_data)
    X, y = split(train_data)
    predictions = predict(X, model)
    error = calculate_error(y, predictions)
    model = update_model(model, error)
```

## SGD&Batch&Epoch的要点

- 随机梯度下降是一种迭代学习算法，它使用训练数据集来更新模型。
- 批量大小是梯度下降的超参数，在模型的内部参数更新之前控制训练样本的数量。
- Epoch数是梯度下降的超参数，控制用于训练的数据集的完整传递次数。

## 神经进化

1. 一种不一样的深度学习
2. 神经网络包括：拓扑、权重、超参数。
3. 神经进化算法不仅会训练和修改网络的权值，同时会修改网络的拓扑结构，包括新增节点和删除节点等操作。

## 双向RNN

1. 双向序列模型有：双向RNN、双向GRU、双向LSTM
2. 双向网络解析：比如，给定一个句子“He said, Teddy Roosevelt”，要判断Teddy是否为人名，这个双向网络就会考虑之前的信息“He said”，也会考虑之后的信息“Roosevelt”，来综合做判断。具体实现为，在同一输入上运行两个循环层，一层从左至右读取单词，另一层从右至左读取单词，然后，只需在每个时间步长上简单地组合它们的输出，通常将它们合并即可。
3. 双向序列模型的优点：可以考虑整个句子的信息，即使在句子中间，也可以综合考虑过去的信息和将来的信息。
4. 双向序列模型的缺点：需要有完整数据的序列，才能预测任意位置。比如，语音识别系统中，必须得等待一个人说完整句话，才能做出识别，有较长的等待时间。
5. 常在NLP中应用，在NLP应用中，常可以获取完整的整个句子。

## 卷积网络CNN

要点：1、CNN模型增强了上下文信息的提取能力
## 其他

1、神经网络算法学习过程具有随机性（如随机梯度下降），即使超参数一样，最后面学习到的模型性能也存在较小偏差。
2、在一维时间序列上使用卷积，这种卷积操作允许网络跨时间共享参数，但是浅层的。卷积的输出是一个序列，其中输出中的每一项是相邻几项输入的函数。参数共享的概念体现在每个时间步中使用的相同卷积核。

# 数学

## 向量减法

向量减法：OA-OB=BA，减向量终点指向被减向量终点，即两向量的差向量方向为减向量指向被减向量。

## 皮尔逊相关系数

**皮尔逊相关系数**(Pearson correlation coefficient，CORR)：用于度量两个变量X和Y之间的相关（线性相关）Pearson系数的变化范围为 -1 到 1 。
**定义：**两个变量之间的皮尔逊相关系数定义为两个变量之间的协方差和标准差的商：
$$
{\rho _{X,Y}} = \frac{{{\mathop{\rm cov}} \left( {X,Y} \right)}}{{{\sigma _X}{\sigma _Y}}} = \frac{{E\left[ {\left( {X - {\mu _X}} \right)\left( {Y - {\mu _Y}} \right)} \right]}}{{{\sigma _X}{\sigma _Y}}}
$$
**解析：**系数的值为 1 意味着 X 和 Y 可以很好的由直线方程来描述，所有的数据点都很好的落在一条直线上，且 Y 随着 X 的增加而增加。系数的值为 -1 意味着所有的数据点都落在直线上，且 Y 随着 X 的增加而减少。系数的值为0意味着两个变量之间没有线性关系。

## 差分

**差分：**相应于微分运算，差分对应离散，微分对应连续。
**差分定义：**设变量 y 依赖于自变量 t ，当 t 变到 t+1 时，因变量 y = y(t) 的改变量 Dy(t) = y(t+1) - y(t) 称为函数 y(t) 在点 t 处步长为1的（一阶）差分，记作Dy~1~ = y~t+1~ - y~t~ ，简称为函数y(t)的（一阶）差分，称D为差分算子。
	一阶前向差分：$\Delta f\left( {{x_k}} \right) = f\left( {{x_{k + 1}}} \right) - f\left( {{x_k}} \right)$
	一阶向后差分：$\Delta f\left( {{x_k}} \right) = f\left( {{x_k}} \right) - f\left( {{x_{k - 1}}} \right)$
	一阶中心差分：$\Delta f\left( {{x_k}} \right) = \frac{1}{2}\left( {f\left( {{x_{k + 1}}} \right) - f\left( {{x_{k - 1}}} \right)} \right)$

## 最小二乘解

**Least-square solution**
1、用于线性方程求解或数据曲线拟合。
2、最小二乘解：利用最小二乘法求得的解。
3、最小二乘法又称为最小平方法，形式如下：标函数 = ∑ (观测值 - 理论值)^2^ 
4、特征：最小化误差的平方和，求得数据的最佳函数匹配。

## 时间复杂度

**常见的时间复杂度：**按数量级递增排列
常数阶O(n)，对数阶O(log2n)，线性阶O(n)，线性对数阶O(nlog2n)，平方阶O(n^2^)，立方阶O(n^3^)，...，k次方阶O(n^k^)，指数阶O(2^n^)

## 标准偏差Std

**Std的求解：**使用原数组，或者使用减掉均值后的数组，对求std不造成差异，结果是相同的。

## 方差

**方差：**实际值与期望值之差平方的平均值。

- 方差越大，说明数据的稳定性差，波动比较大
- 方差小，说明数据比较稳定，数据在平均值上下波动的幅度小
- 作决策时，作为平均值的补充参数。

## 标准化

**标准化的目的**是为了解决不同量纲的问题。只有自变量之间的量纲差异会对参数学习造成影响，因此一般只对自变量进行标准化。

## 统计常用指标

<!--R越大，MAE、MSE、RMSE越小，模型性能越好。-->
<!--没有哪种损失函数适合所有问题，需根据具体模型和问题进行选择。-->
<!--损失函数大致可分为两类：回归和分类。-->

### MRE

MRE：平均相对误差，Mean Relative Error

### C~V~

C~V~：变异系数，Coefficient of Variance。概率分布离散程度的归一化度量。
$$
{c_v} = \frac{\sigma }{\mu } \times 100\% 
$$

- 当需要**比较两组数据离散程度大小**的时候，如果两组数据的测量尺度相差太大，或者数据量纲的不同，直接使用标准差来进行比较不合适，此时应当消除测量尺度和量纲的影响，而变异系数可以做到这一点，变异系数是原始数据标准差与原始数据平均数的比。
- CV是无量纲量，因此在比较两组量纲不同或均值不同的数据时，应该用变异系数而不是标准差来作为比较的参考。
- 可以认为变异系数、极差、标准差和方差一样，都是**反映数据离散程度的绝对值。其数据大小不仅受变量值离散程度**的影响，而且还受**变量值平均水平**大小的影响。
- 变异系数可以消除单位 和（或） 平均数不同对两个或多个资料变异程度比较的影响。
- 在进行数据统计分析时，如果变异系数大于15%，则要考虑该数据可能不正常，应该剔除。
- 两组数据（同类或不同类），在单位相同，但平均数不同，只能用变异系数来比较其变异程度的大小。
- 在利用变异系数表示资料的变异程度时，最好将平均数和标准差也列出。

### C~V~-RMSE

C~V~-RMSE：均方根误差的变异系数
$$
CV - RMSE = \frac{{\sqrt {\frac{1}{n}\sum\nolimits_{i = 1}^n {{{({y_i} - {{\hat y}_i})}^2}} } }}{{\bar y}} \times 100\%
$$

### EEP

EEP：期望相对误差，Expected Error Percentage

### SD

SD：标准差，StandardDevaition。它反映组内个体间的离散程度，一个较低的标准差表示这些值趋向于接近平均（即期望值）的集合，而较高的标准差表示这些值分布在更大的范围内，标准差的平方即方差。

### RMSE/RMSD

RMSE：均方根误差，Root Mean square error，也称RMSD。用于衡量模型预测值和真值(y)之间的偏差。用于识别大误差并评估与方差有关的方法响应中的变化。
RMSD：均方根偏差，Root mean square deviation。
【注】RMSE类似求两个向量的欧氏距离，然后再乘以维数分之一的根
$$
RMSE = \sqrt {\frac{1}{N}\sum\nolimits_{i = 1}^N {{{({y_i} - {{\hat y}_i})}^2}} } 
$$

### RMSLE

RMSLE：均方根对数误差，Root Mean Squared Logarithmic Error
$$
RMSLE = \sqrt {\frac{1}{N}\sum\nolimits_{i = 1}^N {{{(\log \left( {{{\hat y}_i} + 1} \right) - \log \left( {{y_i} + 1} \right))}^2}} }
$$
【注】在keras里的`mean_squared_logarithmic_error`的log的底为e，不是10，log即ln。
**RMSE与RMSLE的对比：**
1、RMSLE惩罚欠预测大于过预测，适用于某些需要欠预测损失更大的场景，如预测共享单车需求。
		假如真实值为1000，若预测值为600，那么RMSE=400，RMSLE=0.510
		假如真实值为1000，若预测值为1400，那么RMSE=400，RMSLE=0.336
		可以看出来，在RMSE相同的情况下，预测值比真实值小这种情况的RMSLE比较大，即对于预测值小这种情况惩罚较大。
2、如果预测的值的范围很大，RMSE会被一些大的值主导。这样即使你很多小的值预测准了，但是有一个非常大的值预测的不准确，RMSE就会很大。
		相应的，如果另外一个比较差的算法对这一个大的值准确一些，但是很多小的值都有偏差，可能RMSE会比前一个小。先取log再求RMSE，可以稍微解决这个问题。
		RMSE一般对于固定的平均分布的预测值才合理。
3、为什么RMSE会被一些大的值主导？我的理解，比如实际值均需大于0，以0为基线，小值距离0近，即需预测的范围小，而大值距离0远，这样需预测的范围就大。
4、当做了标准化或归一化后，用RMSLE会无法学习，因为取对数把值变更小了

### NRMSE

NRMSE：归一化均方根误差，Normalize root means square error

### MSE/MSD

MSE：均方误差，Mean Squared Error，误差平方的平均值，即RMSE的平方，表示设计模型的预测值与实际值之间的均方差。
			别名：均方误差，MSE，二次损失，L2损失（Least square errors）
			因平方的形式利于求导看，所以常被用作线性回归的损失函数。
$$
MSE{\rm{ = }}\frac{1}{N}\sum\nolimits_{i = 1}^N {{{\left( {{y_i} - {{\hat y}_i}} \right)}^2}}
$$

**MSE的特性：**

- 平方误差有个特性，当$y$与${\hat y}$的差值大于1时，会增大其误差；当$y$与${\hat y}$的差值小于1时，会减小其误差。这是由平方的特性决定的。也就是说，MSE会对误差较大（>1）的情况给予更大的惩罚，对误差较小（<1）的情况给予更小的惩罚。从训练的角度来看，模型会更加偏向于惩罚较大的点，赋予其更大的权重。（此处可参考RMSE与RMSLE的对比）。当有异常值存在时，MSE的模型为了能将该单个异常值最小化会牺牲其它常见情况，这降低了模型的整体性能。
- 如果样本中存在离群点，MSE会给离群点赋予更高的权重，但是却是以牺牲其他正常数据点的预测效果为代价，这最终会导致模型的整体性能。使用MSE损失函数，受离群点的影响较大。

### MAE

MAE：平均绝对误差，Mean absolute error。表示模型预测值与实际值之间的平均距离。
			别名：平均绝对误差，MAE，L1损失（Least absolute deviations）
			MAE是散点图中每个点与Y=X线之间的平均绝对垂直或水平距离，即MAE是X和Y之间的平均绝对差。
$$
MAE = \frac{1}{N}\sum\nolimits_{i = 1}^N {\left| {\left( {{y_i} - {{\hat y}_i}} \right)} \right|}
$$

**MAE的特性：**

- MAE的曲线呈V字型，大部分情况下，其梯度都是相等的，这意味着即使对于小的损失值，其梯度也是大的。这不利于函数的收敛和模型的学习。
- MAE与MSE相比，MAE对离群点不那么敏感，更有包容性。因为MAE计算的是误差$(y - \hat y)$的绝对值，无论是$(y - \hat y) > 1$还是$(y - \hat y) < 1$，没有平方项的作用，惩罚力度是一样的，所占权重一样。
- 使用MAE损失函数，受离群点的影响较小，拟合曲线能够较好地表征正常数据的分布情况。这一点上，MAE要优于MSE。
- 如果训练数据被异常值破坏的话（也就是我们在训练环境中错误地接收到巨大的不切实际的正/负值，但在测试环境中却没有），MAE会很有用。

**选择MSE还是MAE：**

- 从计算机求解梯度的复杂度来说，MSE要优于MAE，而且梯度也是动态变化的，能较快准确达到收敛。
- 从离群点角度来看，如果离群点是实际数据或重要数据，而且是应该被检测到的异常值，那么应该使用MSE。如果离群点仅仅代表数据损坏或者错误采样，无须给予过多关注，那么应该使用MAE。
- 简单来说，MSE计算简便，但MAE对异常点有更好的鲁棒性。
- L1损失对异常值更鲁棒，但它的导数是不连续的，从而让它无法有效的求解。L2损失对异常值很敏感，但会求出更稳定和更接近的解（通过将导数设为0）。

**MSE和MAE存在的问题：**

- 可能会出现两种损失函数都无法给出理想预测值的情况。例如，如果我们的数据中90% 的观测值的目标真值为150， 剩余10%的目标值在0-30之间。那么存在MAE损失的模型可能会预测全部观测值的目标值为150，而忽略了那10%的异常情况，因为它会试图趋向于中间值。在同一种情况下，使用MSE损失的模型会给出大量值范围在0到30之间的预测值，因为它会偏向于异常值。在很多业务情况中，这两种结果都不够理想。

**MSE预测平均值，MAE预测中位数的原因：**

- 假设，在训练数据中，对于同一个x，有多个标签y值（实际中，是近似有多个y值）。因为MAE求绝对误差和的平均，众多y值的中位数与这些y值的误差和最小，所以MAE对每个x预测y的中位数。而因为MSE求误差平方和的平均，平方放大了误差，哪种统计量与众多y值相减的平方的和最小呢？也就是众多y值的平均值了。所以MSE对每个x预测y的平均值。
- 差的平方其实就是距离，MSE就是求空间中同时离其他点最近的点，如三个点的话，就是各两点垂直平分线的交点，交点的坐标其实就是各两点坐标的平均值。
- 对于MSE，举个栗子，比如y有（1,2,6）三个值，使用中位数算MSE得17/3，使用平均值算MSE得14/3，平均值能让与各y值的差被平方放大的最小，因此基于MSE的模型趋向于估计一个平均值。
- 由于梯度下降，模型倾向于减少MAE或MSE，进而获得使MAE或MSE最小化的估计量，而中位数使MAE最小，平均数使MSE最小。

### Huber

Huber：平均平滑绝对误差。

- 因为MSE和MAE各有优缺点，Huber Loss对两者综合，来同时消除两者缺点，集合两者优点。

- Huber Loss包含了一个超参数δ，δ值的大小决定了Huber Loss对MSE和MAE的侧重性。当δ->0时，Huber损失会趋向于MAE；当δ->∞（很大的数字）时，Huber损失会趋向于MSE。δ的选择非常关键，它决定了如何看待异常值。

- 通常来说，超参数δ可以通过交叉验证选取最佳值。分别取δ=0.1、δ=1和δ=10，绘制相应的Huber Loss。Huber Loss在${\left| {{y_i} - {{\hat y}_i}} \right| > \delta }$时，梯度一直近似为δ，能够保证模型以一个较快的速度更新参数。当${\left| {{y_i} - {{\hat y}_i}} \right| \le \delta }$时，梯度逐渐减小，能够保证模型更精确地得到全局最优值。因此Huber Loss同时具备了MSE和MAE两种损失函数的优点。

  ![Huber Loss](E:\Python&Algorithm\Dat&AlgorithmNote_image\Huber Loss.png)

- 在优化速度方面，MSE的Loss下降地最快，MAE的Loss下降地最慢，Huber Loss下降速度介于MSE和MAE之间。也就是说，Huber Loss弥补了MAE的Loss下降速度慢的问题，使得优化速度接近MSE。

- 使用Huber Loss作为损失函数，对离群点仍然有很好的抗干扰性，这一点比MSE强。相比平方误差损失，Huber Loss对于数据中异常值的敏感性要差一些。

- Huber Loss基本上是绝对值，在误差很小时会变为平方值。

- 使用Huber损失函数的原因：使用MAE用于训练神经网络的一个大问题就是不变的大梯度，这会导致使用梯度下降训练模型时，在梯度下降快要结束时错过最小值。对于MSE，梯度会随着损失值接近其最小值逐渐减少，从而使其更准确。而Huber Loss会围绕最小值减小梯度，且相比MSE，Huber对异常值更具鲁棒性。但Huber存在一个问题，可能需要训练超参数δ，而且这个过程需要不断迭代。

$$
{L_\delta }\left( {Y,\hat Y} \right) = \frac{1}{N}\sum\nolimits_{i = 1}^N {\left\{ {\begin{array}{*{20}{c}}
{\frac{1}{2}{{({y_i} - {{\hat y}_i})}^2},\quad \quad \;\;\;\left| {{y_i} - {{\hat y}_i}} \right| \le \delta }\\
{\delta \left| {{y_i} - {{\hat y}_i}} \right| - \frac{1}{2}{\delta ^2},\quad \left| {{y_i} - {{\hat y}_i}} \right| > \delta }
\end{array}} \right.} 
$$



### R^2^

R^2^：决定系数，R-square。当建立的模型的准确度越高，R^2^越大。
$$
\begin{array}{c}
{R^2} = 1 - \frac{{\sum\nolimits_{i = 1}^N {{{\left( {{y_i} - {{\hat y}_i}} \right)}^2}} }}{{\sum\nolimits_{i = 1}^N {{{\left( {{y_i} - \bar y} \right)}^2}} }}\\
 = 1 - \frac{{MSE}}{{{\sigma ^2}}}
\end{array}
$$

${{y_i}}$为实际值，${{{\hat y}_i}}$为预测值，${\bar y}$为均值。
### R

R：相关系数，表示设计模型的预测值与实际值之间的相关系数。

###  ${\sigma ^2}$

${\sigma ^2}$：方差，在统计描述中，方差用来度量每一个变量（观察值）与总体均值（即数学期望）之间的偏离程度（差异）。
$$
{\sigma ^2} = \frac{{\sum {{{\left( {X - \mu } \right)}^2}} }}{N}
$$
${\sigma ^2}$为总体方差，X为变量，μ为总体均值，N为总体例数。

### σ

σ：标准差，或标准偏差。方差=标准差的平方。

### MBE

MBE：平均偏移误差，Mean bias error

### MAPE

MAPE：平均绝对百分比误差，Mean absolute percentage error
【注】（1）平均绝对百分比误差可以描述准确度，平均绝对百分比误差常用于衡量预测准确性的统计指标，如时间序列的预测。
（2）要用去归一化或去标准化的数据计算MAPE，使用归一化或标准化的数据计算MAPE是错误的，比如标准化的数据，会因为标准化后，真实值为正，预测值为负，相减距离更大，而去标准化后，真实值和预测值均为正，相减为正确的误差。
（3）当真实值存在0值时，可以在分母加上个接近0的小值。
（4）MAPE范围为[0, +∞]，MAPE为0%表示完美模型，MAPE大于100%则表示劣质模型。
$$
MAPE = \frac{{100\% }}{N}\sum\nolimits_{i = 1}^N {\left| {\frac{{\left( {{y_i} - {{\hat y}_i}} \right)}}{{{y_i}}}} \right|} 
$$


### GCV

GCV：广义交叉验证，Generalized cross-validation criteria

### DTW

DTW：动态时间规整，Dynamic Time Warping

### 交叉熵&KL散度

交叉熵&KL散度：希望预测的概率分布接近观察到的数据的分布，也就是说，希望一种分布（可以是概率向量）与另一种分布接近，而交叉熵和KL散度提供了一种自然的方法测量两个分布之间的差距，这个差距可被当作损失函数。

### 余弦相似度

余弦相似度：Cosine Similarity，也称余弦距离（与欧氏距离区分），是用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小的度量。相比欧氏距离，余弦距离更加注重两个向量在方向上的差异。
		余弦距离是介于-1和1之间的值。余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，这就叫“余弦相似性”。
$$
\begin{array}{c}
\cos \left( \theta  \right) = \frac{{\sum\nolimits_{i = 1}^N {\left( {{x_i} \times {y_i}} \right)} }}{{\sqrt {\sum\nolimits_{i = 1}^N {x_i^2} }  \times \sqrt {\sum\nolimits_{i = 1}^N {y_i^2} } }}\\
 = \frac{{a \bullet b}}{{\left\| a \right\| \times \left\| b \right\|}}
\end{array}
$$
**计算两个向量的相似程度：**

- 可以把两个向量想象成N维空间中的两条线段，都是从原点（[0, 0, ...]）出发，指向不同的方向。两条线段之间形成一个夹角，如果夹角为0°，意味着方向相同、线段重合，这表示两个向量代表的文本完全相等；如果夹角为90°，意味着形成直角，方向完全不相似；如果夹角为180°，意味着方向正好相反。因此，我们可以通过夹角的大小，来判断向量的相似程度。夹角越小，余弦相似度越大，就代表越相似。

**欧氏距离与余弦距离的对比：**

- 欧氏距离衡量的是空间各点的绝对距离，跟各个点所在的位置坐标直接相关。
- 余弦距离衡量的是空间向量的夹角，更加体现在方向上的差异，而不是位置。
- 如果保持A点位置不变，B点朝原方向远离坐标轴原点，那么这个时候余弦距离$\cos \left( \theta  \right)$是保持不变的（因为夹角没有发生变化），而A、B两点的距离显然在发生改变。
- 欧氏距离和余弦距离各自有不同的计算方式和衡量特征，因此它们适用于不同的数据分析模型：
- 欧氏距离能够体现个体数值特征的绝对差异，所以更多的用于需要从维度的数值大小中体现差异的分析，如使用用户行为指标分析用户价值的相似度或差异。
- 余弦距离更多的是从方向上区分差异，而对绝对的数值不敏感，更多的用于使用用户对内容评分来区分兴趣的相似度和差异，同时修正了用户间可能存在的度量标准不统一的问题（因为余弦距离对绝对数值不敏感）。
- 余弦相似度由于对数值的不敏感有时会导致结果的偏差，需要修正这种不合理性就出现了调整余弦相似度，即所有维度上的数值都减去一个均值。算法复杂度虽然增加了，但应该比普通余弦夹角算法要强。



### 式中

N——预测结果的总个数；
${{y_i}}$——真实值；
${{{\hat y}_i}}$——预测值；
${\bar y}$——平均值。

## Accuracy/Precision/Recall

1. **Accuracy：**准确率，分类正确的样本数（包括正样本与负样本） 与 样本总数 之比。用于总体上衡量一个预测的性能。
2. **Precision：**查准率，被正确分类为正样本的样本数 与 被分类为正样本的样本总数 之比。即【宁可漏掉，不可错杀】。
3. **Recall：**查全率，或称召回率，被正确分类为正样本的样本数 与 应当被正确分类为正样本的样本总数 之比。即【宁可错杀，不可漏掉】。

## 分位数

分位数：用概率p作为依据将一批数据分开的点。
常用的有中位数（即二分位数）、四分位数、百分位数等。

1. 二分位数：把所有的同类数据按照大小的顺序排列。如果数据的个数是奇数，则中间那个数据就是这群数据的中位数；如果数据的个数是偶数，则中间那2个数据的算术平均值就是这群数据的中位数。
2. 四分位数：把所有数值由小到大排列并分成四等份，处于三个分割点位置的数值就是四分位数。
   - 第一四分位数(Q1)，又称“较小四分位数”，等于该样本中所有数值由小到大排列后第25%的数字；
   - 第二四分位数(Q2)，又称“中位数”，等于该样本中所有数值由小到大排列后第50%的数字；
   - 第三四分位数(Q3)，又称“较大四分位数”，等于该样本中所有数值由小到大排列后第75%的数字。
   - 第三、四分位数与第一、四分位数的差距又称四分位距（InterQuartile Range,IQR）。
3. 百分位数：如果将一组数据从小到大排序，并计算相应的累计百分位，则某一百分位所对应数据的值就称为这一百分位的百分位数。

## 梯度

- 梯度是一个向量（矢量），它是一种关于多元导数的概括。
- 一元函数的导数是标量值函数（只有数值，没有方向），多元函数的梯度是向量值函数。
- 多元可微函数f在点P上的梯度，是以f在P上的偏导数为分量组成的向量。
- 一元函数的导数表示这个函数图形的切线的斜率。
- 多元函数在点P上的梯度不是零向量时，它的方向时这个函数在P上最大增长的方向、它的量（梯度的模）是在这个方向的增长率。
- 多元函数沿梯度方向，数值增长最快。

![Gradient](E:\Python&Algorithm\Dat&AlgorithmNote_image\Gradient.svg)
上面两个图中，标量场的值用灰度表示，越暗表示越大的数值，而其相应的梯度用蓝色箭头表示。

## 偏度和峰度

### 偏度

**偏度**(Skewness)用来度量随机变量概率分布的不对称性。
几何意义：偏度取值范围为(-∞，+∞)
当偏度<0时，概率分布图左偏
当偏度=0时，表示数据相对均匀的分布在平均值两侧，不一定是绝对的对称分布。
当偏度>0时，概率分布图右偏。

### 峰度

**峰度(Kurtosis)**用来度量随机变量概率分布的陡峭程度。
几何意义：
峰度的取值范围为[1，+∞)，完全服从正态分布的数据的峰度值为3，峰度值越大，概率分布图越高尖，峰度值越小，越矮胖。

## 对偶问题

1、对偶是指对同一事物（问题）从不同的角度（立场）观察，有两种拟似对立的表述。
2、平面中矩形的面积与周长的关系：
	  a.周长一定，面积最大的矩形是正方形
	  b.面积一定，周长最短的矩形是正方形
3、同一个数据集的线性规划问题——生产规划：
	  a.以最大利润为目标函数
	  b.以最小资源消耗为目标
4、线性规划的对偶问题：
	  对于同一数据集，
	  原问题——“<=”不等式约束条件和目标函数最大化
	  对偶问题——“>=”不等式约束条件和目标函数最小化

## 多目标优化问题

1、多目标优化问题中，每个目标不可能都同时达到最优，必须各有权重。而如何分配权重已是研究热点问题。利用遗传算法的全局搜素能力，避免传统的多目标优化方法在寻优过程中陷入局部最优解，可使解个体保持多样性。
2、在单目标优化问题中，通常最优解只有一个，而在多目标优化问题中，各个目标之间相互制约，可能使得一个目标性能的改善往往是以损失其它目标性能为代价，不可能存在一个使所有目标性能都达到最优的解，所以对于多目标优化问题，其解通常是一个非劣解的集合——Pareto解集。
3、在存在多个Pareto最优解的情况下，如果没有关于问题的更多信息，很难选择哪个解更可取，因此所有的Pareto最优解都可以被认为是同等重要的。对于多目标优化问题，最重要的任务是找到尽可能多的关于该优化问题的Pareto最优解。
4、目前求解帕累托前沿解的主要算法有基于数学的规划方法和基于遗传算法的方法(如NSGA-Ⅱ)，多目标遗传算法的核心是协调各个目标函数之间的关系，找出使得各个目标函数都尽可能达到比较大的(或比较小的)函数值的最优解集。
5、多目标优化的经典算法：(1)线性加权法；(2)主要目标法；(3)逼近目标法；(4)梯度下降算法

[^注]: (1)(2)(3)为采取先验的知识来将多目标优化问题简化为单目标优化问题，在一些严格的条件下，能够得到有效解(弱有效解)。

6、多目标优化的目的是获得帕累托最优解。

## 线性

### 几何理解

线性在二维里表现为直线，即$y = ax + b$；线性在三维里表现为平面，即$y = a{x_1} + b{x_2} + c$。以此类推更高维度。

【注】曲线：任何一根连续的线条都称为曲线。包括直线、折线、线段、圆弧等。

### 数值理解

线性在数值上，表现为不同维度在放缩和叠加上相应保持一致，即线性在各维度只进行了放缩和叠加。
可加性：$f(x + y) = f(x) + f(y)$.
齐次性：$f(\alpha x) = \alpha f(x)$.

### 线性模型

- 线性模型可以模拟曲线（特指曲折的曲线）与曲面
- 线性定义：一个表达式是否为线性，取决于参数，而不是自变量

$$
Y = {\beta _0} + {\beta _1}{X_1} + {\beta _2}X_2^2
$$

- 当自变量平方后，模型在参数上仍然是线性的。线性模型也可以包含对数项和逆向，以遵循不同类型的曲线，但参数仍然是线性的，所以只要参数是线性的，变量是二次方、多次方或者指数、对数，都不会改变模型的线性本质。


## 非线性

- 非线性模型：判断一个模型是不是非线性，就是判断它的参数是不是非线性
- 注：各个参数间不是非线性，即一个自变量的参数间不是仅加减法。如一个自变量有两个参数，两个参数相乘，$Y = abX$，则为非线性模型。
- 非线性有非常多的不规则的表达，这也是非线性模型能够那么好的拟合那些曲折的函数曲线的原因，进而产生更加优异的泛化效果。

$$
\begin{array}{l}
Y = \omega  * {x^\nu }\\
Y = \omega  + \left( {{\nu _1} - {\nu _2}} \right) * {e^{2 * x}}
\end{array}
$$

​			深度学习中的非线性表示：输入和输出经过中间多个隐藏层，输入和输出的关系中，一个自变量的多个参数呈现相乘表示及激活函数表示等。
![深度网络的非线性表示](E:\Python&Algorithm\Dat&AlgorithmNote_image\深度网络的非线性表示.jpg)


## 卷积

### 缩写

- 卷积：Convolution
- 卷积计算层：CONV，线性乘积求和。池化层：POOL，取区域平均或最大。
- 卷积神经网络：CNN，Convolutional Neural Network

### 卷积物理意义

- 卷积的物理意义是：一个函数（如：单位响应）在另一个函数（如：输入信号）上的加权叠加。
- 卷积的意义就是加权叠加。
- 对于线性时不变系统，如果知道该系统的单位响应，那么将单位响应和输入信号求卷积，就相当于把输入信号的各个时间点的单位响应加权叠加，就直接得到了输出信号。
- 通俗的说，在输入信号的每个位置，叠加一个单位响应，就得到了输出信号。
- 也可以理解为，某一时刻的输出是之前很多次输入乘以各自的衰减系数之后的叠加而形成某一点的输出，然后再把不同时刻的输出点放在一起，形成一个函数，这就是卷积。

### 卷积数学表示

当卷积的变量是序列$x\left( n \right)$和$h\left( n \right)$，则卷积的结果是：
$$
y\left( n \right) = x\left( n \right) * h\left( n \right)
$$
当卷积的变量是函数$f\left( x \right)$和$g\left( x \right)$，则卷积的结果是：
$$
y\left( x \right)=\int_{ - \infty }^\infty  {f\left( \tau  \right)} g\left( {x - \tau } \right)d\tau=f\left( x \right) * g\left( x \right)
$$

### 卷积作用

消除噪声、特征增强

## 回归分析

### 回归分析的五个基本假设

#### 线性性&可加性

假设因变量为Y，自变量为X~1~，X~2~，则回归分析的默认假设为$Y = b + {a_1}{X_1} + {a_2}{X_2} + \varepsilon $。
线性性：X~1~每变动一个单位，Y相应变动a~1~个单位，与X~1~的绝对数值大小无关。
可加性：X~1~对Y的影响是独立于其他自变量（如X~2~）的。

#### 自变量（X1,X2）之间应相互独立

若不满足这一特性，称模型具有多重共线性性。

#### 误差项ε之间应相互独立

若不满足这一特性，称模型具有自相关性。

#### 误差项ε的方差应为常数

若满足这一特性，称模型具有同方差性；若不满足这一特性，称模型具有异方差性。

#### 误差项ε应呈正态分布


## 残差分析

在回归模型$y = {\beta _0} + {\beta _1}x + \varepsilon $中，确定有关误差项ε的假设是否成立的方法之一是进行残差分析。

### 残差

残差：residual，是因变量的观测值${{y_i}}$与根据估计的回归方程求出的预测${{{\hat y}_i}}$之差，用e表示。反映了用估计的回归方程去预测${{y_i}}$而引起的误差。
第i个观测值的残差为：${e_i} = {y_i} - {{\hat y}_i}$

### 残差图

- 常用残差图：有关x残差图，有关${{\hat y}_i}$的残差图，标准化残差图
- **有关x残差图：**用横轴表示自变量x的值，纵轴表示对应残差${e_i} = {y_i} - {{\hat y}_i}$，每个x的值与对应的残差用图上的一个点来表示。
- **有关${{\hat y}_i}$的残差图：**用横轴表示拟合值${{\hat y}_i}$，纵轴表示对应残差${e_i} = {y_i} - {{\hat y}_i}$，每个${{\hat y}_i}$的值与对应的残差用图上的一个点来表示。

### 频谱分析法

​		根据傅里叶级数表示法，任何一个函数都可以表示为一系列不同频率正弦和余弦函数之和，所以任何波形的波都可以归结为一系列不同频率简谐波的叠加。这种分析方法称为**频谱分析法**。

## 傅里叶变换

1. 正弦函数
    $$x = A\sin \left( {\omega t + \varphi } \right) = A\sin \left( {{{2\pi } \over T}t + \varphi } \right) = A\sin \left( {2\pi ft + \varphi } \right)$$
    <font color=blue> 其中，A为振幅，${\omega t + \varphi }$ 为相位，ω是角/圆频率，$\varphi $ 是初相位，T是周期，f是频率。 </font>

2. 时域图：横坐标-时间，纵坐标-幅度
3. 频域图：横坐标-频率，纵坐标-幅度。频率加振幅决定一个正弦波。
4. 相位谱：横坐标-频率，纵坐标-相位差（取值范围为 $ - \pi  \le \Delta \varphi  \le \pi $ ，频率加相位差决定一个正弦波，相位差为时间差除所在频率的周期。
   
   > 注：该相位差与一般相位差不同。

5. 傅里叶变换：任何周期函数，都可以看作是不同振幅、不同相位正弦波的叠加。
6. 傅里叶级数：在时域是一个周期且连续的函数，在频域是一个非周期离散的函数。
   
   > 则傅里叶变换是将一个时域非周期的连续信号，转换为一个在频域非周期的连续信号。

7. 欧拉公式
   $${e^{ix}} = \cos x + i\sin x$$


# Glossary of terms

## 迁移学习

**Transfer Learning**

- Model Fine-tuning：模型微调
		训练技巧：
			Conservative Training：保守训练
			Lay Transfer：层迁移
- Multitask Learning：多任务学习
- Progressive Neural Networks：渐进神经网络
- Domain-adversarial training：领域对抗训练
- Zero-shot Learning：零样本学习
- Self-taught Learning：自我学习
- Self-taught Clustering：自我聚类

## 回归评价指标

- MAE：平均绝对误差，Mean Absolute Error
- MAPE：平均绝对百分比误差，Mean Absolute Percentage Error
- MSE：均方误差，Mean Square Error
- RMSE：均方根误差，Root Mean Square Error
- R2：决定系数，R-Square

## 决策树量化分类效果方式

- ID3：信息增益
- C4.5：信息增益率
- CART：基尼系数，Classification And Regression Tree，分类回归树

## Other

- ML：机器学习
- DL：深度学习
- NLP：自然语言处理，Natural Language Processing
- CV：计算机视觉，Computer Vision
- CV：交叉验证，Cross Validation
- MV：机器视觉，Machine Vision
- API：应用程序编程接口，Application Programming Interface
- 不可判定问题：“不可能”解出的问题
- 判定问题：判断是否有一种能够解决某一类问题的算法的研究课题
- P问题：能够在多项式时间内用算法求解的问题，Polynomial-time
- NP问题：不确定是否存在多项式时间的求解算法，但可以在多项式时间内验证一个猜测解的
- 正确性的问题，非确定型多项式时间可解的判定问题
- NPH问题：NP hard问题，如果所有NP问题都可在多项式时间内归约成某个问题，则该问题称为NP hard问题
- NPC问题：如果所有NP问题都可在多项式时间内归约成某个NP问题，则该NP问题称为NP完全问题
- QP问题：二次规划问题，Quadratic Programming
- LP问题：线性规划，Linear Programming
- DP问题：动态规划
- QCQP问题：二次约束二次规划问题
- IDE：集成开发环境，Integrated Development Environment
- DLL：动态链接库，Dynamic Link Library，一个包含可由多个程序，同时使用的代码和数据的库
- 集成学习：Ensemble Learning，Boosting与Bagging
- KMP算法：在一个已知字符串中查找子串的位置、
- Boosting：提升算法
- Bagging：装袋算法，Boostrap aggregating
- XGBoost：极限梯度提升，eXtreme Gradient Boosting
- GBDT：梯度提升决策树，Gradient Boosting Decision Tree
- AdaBoost：自适应增强，Adaptive Boosting
- CART：分类回归树，Classification And Regression Tree
- 模型平均：ModelAveraging
- 数据泄露：用于训练的数据集中包含将要预测事务的东西，将预测目标作为模型的特征
- RFE：递归特征消除，Recursive Feature Elimination
- ACF图：自相关图
- PACF图：偏自相关图
- ADF检验：单位根检验，Augmented Dickey-Fuller test
- mini-batch：批量梯度下降
- GMM：Gaussian Mixture Model
- Fourier Transform：傅里叶变换
- SVD：奇异值分解
- LDA：线性判别降维方法，Linear Discriminant Analysis
- NMF：非负矩阵分解，Non-negative matrix factorization
- Manifold learning：流形学习
- Euclidean distance：欧几里得距离
- LLE：局部线性嵌入，Locally Linear Embeddin
- T-SNE：T-分布随机领域，T-distributed Stochastic Neighbor Embedding
- LSA：潜在语义分析，Latent semantic analysis
- Generative Models：生成模型
- GNN：Graph Neural Network
- PixelRNN
- VAE：Variational Autoencoder
- Gaussian Mixture Model：高斯混合模型
- GAN：生成对抗网络，Generative Adversarial Network
- Quadratic Programming（QP）Problem：二次规划问题
- Dual Representation：对偶性
- Kernel trick：核函数
- Radial Basis Function Kernel：径向基函数核
- Sigmoid Kernel
- SLFN：单隐藏层前馈神经网络
- EM：最大期望算法，Expectation-Maximization
- DBN：深度信念网络，Deep Belief Network
- RBM：受限玻尔兹曼机，Restricted Boltzmann Machine
- CD：对比散度学习算法，Contrastive Divergence
- PLSR：偏最小二乘回归法，Partial Least Squares Regression
- Branch and Bound algorithm：分支定界法
- Selective Search：选择性搜索
- Sequence Labeling：序列标记
- Cutting Plane Algorithm：割平面法
- Structured perceptron：结构化感知机
- slack variable：松弛变量
- ELM：极限学习机，Extreme Learning Machine
- HMM：隐马尔科夫模型，Hidden Markov Model
- CRF：条件随机场，Conditional Random Field
- Viterbi algorithm：维特比算法
- MLP：多层感知机，Multilayer Perceptron，也叫人工神经网络
- ANN：人工神经网络，Artificial Neural Network
- DNN：深度神经网络，Deep Neural Networks
- RNN：循环神经网络/递归神经网络，Recurrent Neural Network，时间递归神经网络(recurrent neural network)，结构递归神经网络(recursive neuralnetwork)
- CNN：卷积神经网络，Convolutional Neural Network
- LSTM：长短期记忆网络，RNN的进阶版，Long Short - - Term Memory networks，有三个gate
- GRU：门控循环神经网络，Gated Recurrent Unit neural network
- BPTT：时间反向传播，Backpropagation through time，RNN的训练使用BPTT，每个输出的梯度不仅依赖当前时刻的计算，还依赖之前时刻的计算。
- GRU：Gated Recurrent Unit，有两个gate，“旧的不去新的不来”，”把memory里的值清掉，才能把新的值放入“。
- identity matrix：单位矩阵
- temporal：暂时的，时间的
- Life Long Learning：终身学习
- Meta-learning/Learn to learn：元学习，学习如何学习
- Network Compression：神经网络压缩
- Unsupervised Domain Adaptation：无监督领域自适应
- Data Augmentation：数据增强
- IG：Integrated gradient，积分梯度
- MTL：多任务学习，Multi-task Learning
- Time Granularity/grain/interval：时间粒度，即频率或时间间隔

## Word Cheat Sheet

demo：示范
batchsize：批量大小
coef：系数
coefficient：折算率
intercept：截距
recursively：递归地
categorical：绝对的
epoch：时代，时期
tune：调整
converge：收敛
yield：产生
convolutional：卷积的
cross entropy：交叉熵
dir：目录
NaN：缺失数据填补
accuracy：准确度，精度
metrics：度量 
dropout：信息丢弃
args：位置参数，*参数名称
kwargs：关键字参数，**参数名称 
piecewise：分段的
convex：凸出的
guarantee：确保
movement：运动
momentum：势头
ensemble：整体
approximate：近似 
saddle point：鞍点
critical point：驻点，临界点
positive definite：正定的
eigen values：特征值
error surface：误差曲面
rugged：崎岖的
stuck：卡住的
hyperparameter：超参数
shuffle：重新洗牌
vanilla：一般的，香草
critical point：临界点
warm up：准备活动，热身
magnitude：大小
inception：开始
covariate shift：协变量转变
subsampling：二次抽样
convolution：卷积
pooling：池化
stride：步距
tensor：高维的matrix，张量
flatten：变平
constraint：约束
architecture：架构，结构
Spectrogram：光/声谱图
filter：过滤器
anomaly：异常，不规则
recipe：诀窍
array：数组，阵列
modularization：模组化
Phoneme：音素，音标
acoustic：声的
articulation：发音
Universality：普遍性
Theorem：定理
shallow：浅的
analogy：类比
simpler：更简单
parity：相等
hypothesis：假设
Impute：灌输
transductive learning：直推学习
inductive learning：归纳学习
posterior probability：后验概率
self-training：自我训练
enumerate：枚举
proportional：成比例的
exponential：指数的，exp
propagate：传播
Distributed Representation：分布式表征
Dimension Reduction：降维
Orthogonal matrix：正交矩阵
eigen：特征的
eigen vector：特征向量 
decorrelation：去相关
reconstruction error：重构误差
component：成分，部件
linear transformation：线性变换
Autoencoder：自编码
factorization：因式分解
latent：隐藏的
inverse：相反，倒转
embed：嵌入
semantic：语义
bag-of-word：词袋
neighbor：邻近
map：映射
Laplacian Eigenmaps：拉普拉斯特征映射
manifold：流形
summation：和
retrieval：检索
pre-training：预训练
find tune：微调
variational：变化的
estimate：估计，评价
probability distribution：概率分布
variance：方差
multinomial：多项式
lower bound：下界
appendix：附录
combination：组合
discriminator：辨别器
one-shot：只有一次的
transcription：音译
generalization：泛化
mismatch：不匹配
outlier：离群值
sparse：稀疏的
inner product：内积，点积，数量积
cross product：外积，叉积，向量积
unified：统一的
compatible：兼容的
inference：推断结果
summarization：摘要
evaluation：评估
perceptron algorithm：感知机算法
terminate：终止
explicit：清楚明白的
separable：可分的
normalization：标准化，归一化
regularization：正则化
rescale：重放缩，重新调整
weight decay：权重衰减
scalar：标量
arbitrary identifier string：任意的标识符字符串
transformer：转换器
estimator：估计函数
demonstration：演示，Demo
decomposition：分解 
termination：终止
joinly trained：一起训练
annotate：注释
transition probability：转移概率
emission probability：发散概率
tag：标签
synthetic：合成的，人造的
P(x|y)：P of x given y；P(y)：P of y；P(x,y)：P of x，y
slot：槽
bidirectional：双向的
gate：闸门
clipping：裁剪
format：格式化
sentiment analysis：情感分析
alignment：对齐，一致
syntactic parsing：句法分析
architecture：结构
stump：树桩
warning：警示
aggregate：总计
summation：总计
chat-bot：聊天机器人
episode：一段经历、一段时期
defferentiable：可微的
cumulative：累积的
augmentation：增加，增强
flip：快速翻转
padding：填补，补值
slide：滑行
one-hot：独热码
tagging：标记
query：疑问
column：列
position：位置
alignment：一致
lossy：失真
compression：压缩
decompression：解压缩
Anomaly Detection：异常检测
proxy：代理
synthesized：合成的
interpretable：可说明的
probe：探究
adversarial：对抗的
